{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Task 1: Importing Libraries","metadata":{}},{"cell_type":"code","source":"import keras\nimport os\nimport shutil\nimport numpy as np\nimport math\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom platform import python_version\n\nprint('Python version:', python_version())\nprint('Numpy version:', np.__version__)\nprint('Seaborn version:', sns.__version__)\nfrom distutils.dir_util import copy_tree\nimport tensorflow as tf\nprint('tensorflow version: ',tf.__version__)\nprint('keras version:', keras.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-30T11:27:23.205879Z","iopub.execute_input":"2023-04-30T11:27:23.206291Z","iopub.status.idle":"2023-04-30T11:27:30.212404Z","shell.execute_reply.started":"2023-04-30T11:27:23.206255Z","shell.execute_reply":"2023-04-30T11:27:30.211258Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Python version: 3.7.6\nNumpy version: 1.18.5\nSeaborn version: 0.10.0\ntensorflow version:  2.3.1\nkeras version: 2.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.layers import Dropout\nfrom keras_preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-04-30T11:27:30.214572Z","iopub.execute_input":"2023-04-30T11:27:30.214999Z","iopub.status.idle":"2023-04-30T11:27:30.221230Z","shell.execute_reply.started":"2023-04-30T11:27:30.214957Z","shell.execute_reply":"2023-04-30T11:27:30.219992Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Task 2: Dataset Creation","metadata":{}},{"cell_type":"code","source":"#created data set using console\nsource='../input/african-wildlife/'\ntarget='./train_data/'\nshutil.copytree(source, target)\nos.mkdir('test_data')","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:30.222790Z","iopub.execute_input":"2023-04-30T11:27:30.223209Z","iopub.status.idle":"2023-04-30T11:27:48.084476Z","shell.execute_reply.started":"2023-04-30T11:27:30.223164Z","shell.execute_reply":"2023-04-30T11:27:48.083455Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# remove unwanted data and create same classed for test_data\n\npath=\"./train_data/\"\nfor file in os.listdir(path):\n    for image in os.listdir(path+file+'/'):\n        if '.jpg' not in image:\n            os.remove(path+file+'/'+image)\n    os.mkdir('./test_data/'+file)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.085696Z","iopub.execute_input":"2023-04-30T11:27:48.085998Z","iopub.status.idle":"2023-04-30T11:27:48.126353Z","shell.execute_reply.started":"2023-04-30T11:27:48.085969Z","shell.execute_reply":"2023-04-30T11:27:48.125158Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# create test_data by taking 25% images from data\n\ntotal_train_images,total_test_images,total_train_classes,total_test_classes=0,0,0,0\npath=\"./train_data/\"\nfor file in os.listdir(path):\n    total_train_classes+=1\n    total_images=len(os.listdir(path+file+\"/\"))\n    test_image_count=(25/100)*total_images #25% for test and 75% for train\n    for i in range(math.ceil(test_image_count)):\n        img=random.choice(os.listdir(path+file+'/'))\n        shutil.move(path+file+'/'+img,'./test_data/'+file+'/')\n        #print(img)\n    print(file,total_images,math.ceil(test_image_count))\n    total_train_images+=(total_images-math.ceil(test_image_count))\n    #print(file,math.ceil(test_image_count))\nprint(\"total train images are : \",total_train_images,\" and total train classes are : \",total_train_classes)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.129201Z","iopub.execute_input":"2023-04-30T11:27:48.129557Z","iopub.status.idle":"2023-04-30T11:27:48.223187Z","shell.execute_reply.started":"2023-04-30T11:27:48.129522Z","shell.execute_reply":"2023-04-30T11:27:48.222189Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"rhino 375 94\nelephant 375 94\nzebra 376 94\nbuffalo 375 94\ntotal train images are :  1125  and total train classes are :  4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Task 3: Model Creation","metadata":{}},{"cell_type":"code","source":"model = Sequential()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.226402Z","iopub.execute_input":"2023-04-30T11:27:48.226839Z","iopub.status.idle":"2023-04-30T11:27:48.288632Z","shell.execute_reply.started":"2023-04-30T11:27:48.226785Z","shell.execute_reply":"2023-04-30T11:27:48.287460Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#inputlayer : apply filters\nmodel.add(Convolution2D(filters=32, \n                        kernel_size=(3,3),\n                        strides=(1,1),\n                        padding='same',\n                        activation='relu',\n                   input_shape=(32, 32, 1)))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.290452Z","iopub.execute_input":"2023-04-30T11:27:48.290882Z","iopub.status.idle":"2023-04-30T11:27:48.344098Z","shell.execute_reply.started":"2023-04-30T11:27:48.290836Z","shell.execute_reply":"2023-04-30T11:27:48.343252Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# pooling layer where we are doing maxpooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.345374Z","iopub.execute_input":"2023-04-30T11:27:48.345661Z","iopub.status.idle":"2023-04-30T11:27:48.352611Z","shell.execute_reply.started":"2023-04-30T11:27:48.345627Z","shell.execute_reply":"2023-04-30T11:27:48.351296Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#adding one more convolution layer for better model\nmodel.add(Convolution2D(filters=32, \n                        kernel_size=(3,3),\n                        strides=(1,1),\n                        padding='same', \n                        activation='relu'\n                      ))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.354052Z","iopub.execute_input":"2023-04-30T11:27:48.354443Z","iopub.status.idle":"2023-04-30T11:27:48.373481Z","shell.execute_reply.started":"2023-04-30T11:27:48.354402Z","shell.execute_reply":"2023-04-30T11:27:48.372467Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#adding one more Pooling layer for better model\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.374734Z","iopub.execute_input":"2023-04-30T11:27:48.375528Z","iopub.status.idle":"2023-04-30T11:27:48.383782Z","shell.execute_reply.started":"2023-04-30T11:27:48.375484Z","shell.execute_reply":"2023-04-30T11:27:48.382317Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#dropout regularlization\nmodel.add(Dropout(0.5))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.387144Z","iopub.execute_input":"2023-04-30T11:27:48.387466Z","iopub.status.idle":"2023-04-30T11:27:48.429086Z","shell.execute_reply.started":"2023-04-30T11:27:48.387428Z","shell.execute_reply":"2023-04-30T11:27:48.428235Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#layer in which we are converting 2d/3d image to 1d image i.e flattening\nmodel.add(Flatten())","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.430248Z","iopub.execute_input":"2023-04-30T11:27:48.430716Z","iopub.status.idle":"2023-04-30T11:27:48.440250Z","shell.execute_reply.started":"2023-04-30T11:27:48.430684Z","shell.execute_reply":"2023-04-30T11:27:48.439217Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# layer: appling relu to give positive output from here our hidden layerrs starts\nmodel.add(Dense(units=20, activation='relu'))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.441455Z","iopub.execute_input":"2023-04-30T11:27:48.441775Z","iopub.status.idle":"2023-04-30T11:27:48.456222Z","shell.execute_reply.started":"2023-04-30T11:27:48.441746Z","shell.execute_reply":"2023-04-30T11:27:48.455267Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#dropout regularlization\nmodel.add(Dropout(0.5))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.457604Z","iopub.execute_input":"2023-04-30T11:27:48.457895Z","iopub.status.idle":"2023-04-30T11:27:48.474151Z","shell.execute_reply.started":"2023-04-30T11:27:48.457868Z","shell.execute_reply":"2023-04-30T11:27:48.473204Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# output layer : Since we have to do multi-class classification so we'll apply softmax activation function \n# we have 4 classes of animals so output layer would have that many neurons.\nmodel.add(Dense(units=4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.475598Z","iopub.execute_input":"2023-04-30T11:27:48.476114Z","iopub.status.idle":"2023-04-30T11:27:48.490552Z","shell.execute_reply.started":"2023-04-30T11:27:48.476071Z","shell.execute_reply":"2023-04-30T11:27:48.489412Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.491662Z","iopub.execute_input":"2023-04-30T11:27:48.492141Z","iopub.status.idle":"2023-04-30T11:27:48.505731Z","shell.execute_reply.started":"2023-04-30T11:27:48.492096Z","shell.execute_reply":"2023-04-30T11:27:48.504423Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.507539Z","iopub.execute_input":"2023-04-30T11:27:48.507865Z","iopub.status.idle":"2023-04-30T11:27:48.518239Z","shell.execute_reply.started":"2023-04-30T11:27:48.507835Z","shell.execute_reply":"2023-04-30T11:27:48.517238Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 32, 32)        320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n_________________________________________________________________\ndropout (Dropout)            (None, 8, 8, 32)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 20)                40980     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 20)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 4)                 84        \n=================================================================\nTotal params: 50,632\nTrainable params: 50,632\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Task 4: Image Augmentation","metadata":{}},{"cell_type":"code","source":"#url : https://keras.io/api/preprocessing/image/ \ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntraining_set = train_datagen.flow_from_directory(\n        './train_data/',\n        target_size=(32,32),\n        color_mode=\"grayscale\",\n        batch_size=64,\n        class_mode='categorical')\ntest_set = test_datagen.flow_from_directory(\n        './test_data/',\n        target_size=(32,32),\n        color_mode=\"grayscale\",\n        batch_size=64,\n        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.519490Z","iopub.execute_input":"2023-04-30T11:27:48.519784Z","iopub.status.idle":"2023-04-30T11:27:48.734255Z","shell.execute_reply.started":"2023-04-30T11:27:48.519755Z","shell.execute_reply":"2023-04-30T11:27:48.733142Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Found 1125 images belonging to 4 classes.\nFound 376 images belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_set.class_indices # to see classes of our dataset","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.735479Z","iopub.execute_input":"2023-04-30T11:27:48.735758Z","iopub.status.idle":"2023-04-30T11:27:48.742943Z","shell.execute_reply.started":"2023-04-30T11:27:48.735730Z","shell.execute_reply":"2023-04-30T11:27:48.742051Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'buffalo': 0, 'elephant': 1, 'rhino': 2, 'zebra': 3}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Task 5: Model Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n        training_set,\n        steps_per_epoch=(1125/64),\n        epochs=100,\n        validation_data=test_set,\n        validation_steps=(376/64))","metadata":{"execution":{"iopub.status.busy":"2023-04-30T11:27:48.744500Z","iopub.execute_input":"2023-04-30T11:27:48.744793Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/100\n18/17 [==============================] - 28s 2s/step - loss: 1.3902 - accuracy: 0.2569 - val_loss: 1.3838 - val_accuracy: 0.2500\nEpoch 2/100\n18/17 [==============================] - ETA: 0s - loss: 1.3858 - accuracy: 0.2551","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Task 6: Accuracy","metadata":{}},{"cell_type":"code","source":"#Graphing our training and validation\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'r', label='Training acc')\nplt.plot(epochs, val_accuracy, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.ylabel('accuracy') \nplt.xlabel('epoch')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.ylabel('loss') \nplt.xlabel('epoch')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save(\"simple_animal_classification_model.h5\")#save model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from keras.models import load_model\n#model=load_model(\"simple_animal_classification_model.h5\") ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Task 7: Testing","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing import image\ntest_image = image.load_img(\"../input/african-wildlife/zebra/001.jpg\",target_size=(32,32),color_mode='grayscale')\ntest_image \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image,axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = model.predict(test_image)\n\nmy_dict=training_set.class_indices\ndef get_key(val): \n    for key, value in my_dict.items(): \n         if val == value: \n             return key \n  \n    return \"key doesn't exist\"\n\npred=list(result[0])\nfor i in range(len(pred)):\n    if pred[i]!=0:\n        print(get_key(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}